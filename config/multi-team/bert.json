// The base configuration for UD parsing
{
  "dataset_reader": {
    "lazy": false,
    "type": "udify_universal_dependencies",
    "token_indexers": {
      "tokens": {
        "type": "single_id",
        "lowercase_tokens": true
      },
      "token_characters": {
        "type": "characters"
      },
      "bert": {
        "type": "udify-bert-pretrained",
        "pretrained_model": "config/archive/bert-base-multilingual-cased/vocab.txt",
        "do_lowercase": false,
        "use_starting_offsets": true
      }
    }
  },
  "vocabulary": {
    "directory_path": "data/vocab/multilingual/vocabulary",
    "non_padded_namespaces": ["upos", "xpos", "feats", "lemmas", "langs","*tags", "*labels"]
  },
  "train_data_path": "data/ud/multilingual/train.conllu",
  "validation_data_path": "data/ud/multilingual/dev.conllu",
  "test_data_path": "data/ud/multilingual/test.conllu",
  "evaluate_on_test": true,
  "model": {
    "type": "udify_model",
    "word_dropout": 0.2,
    "layer_dropout": 0.1,
    "tasks": ["upos", "feats", "lemmas", "deps"],
    "dropout": 0.0,
    "text_field_embedder": {
      "type": "basic",
      "allow_unmatched_keys": true,
      "embedder_to_indexer_map": {
        "bert": ["bert", "bert-offsets"]
      },
      "token_embedders": {
        "bert": {
          "type": "udify-bert-pretrained",
          "pretrained_model": "bert-base-multilingual-cased",
          "requires_grad": false,
          "dropout": 0.15,
          "layer_dropout": 0.1,
          "combine_layers": "last"
        }
      }
    },
    "encoder": {
      "type": "lstm",
      "bidirectional": true,
      "input_size": 768,
      "hidden_size": 1024,
      "num_layers": 1,
      "dropout": 0.2
    },
    "decoders": {
      "upos": {
        "type": "udify_tag_decoder",
        "task": "upos",
        "encoder": {
          "type": "pass_through",
          "input_dim": 2048
        }
      },
      "feats": {
        "type": "udify_tag_decoder",
        "task": "feats",
        "encoder": {
          "type": "pass_through",
          "input_dim": 2048
        },
        "adaptive": true
      },
      "xpos": {
        "type": "udify_tag_decoder",
        "task": "xpos",
        "encoder": {
          "type": "pass_through",
          "input_dim": 2048
        },
        "adaptive": true
      },
      "lemmas": {
        "type": "udify_tag_decoder",
        "task": "lemmas",
        "encoder": {
          "type": "pass_through",
          "input_dim": 2048
        },
        "adaptive": true
      },
      "deps": {
        "type": "udify_dependency_decoder",
        "pos_embed_dim": null,
        "tag_representation_dim": 256,
        "arc_representation_dim": 768,
        "encoder": {
          "type": "pass_through",
          "input_dim": 2048
        }
      }
    }
  },
  "iterator": {
    "type": "bucket",
    "batch_size": 16,
    "sorting_keys": [["tokens", "num_tokens"]],
    "biggest_batch_first": true,
    "maximum_samples_per_batch": ["num_tokens", 16*100]
  },
  "trainer": {
    "optimizer": {
      "type": "adam",
      "lr": 1e-4,
      "betas": [0.9, 0.99],
      "weight_decay": 0.0
    }/*,
    "learning_rate_scheduler": {
      "type": "multi_step",
      "milestones": [0, 1, 15, 20, 30, 40],
      "gamma": 0.5
    }*/,
    "num_epochs": 100,
    "patience": 5,
    "validation_metric": "+.run/.sum",
    "should_log_learning_rate": false,
    "should_log_parameter_statistics": false,
    "summary_interval": 500,
    "num_serialized_models_to_keep": 1,
    "grad_norm": 1.0,
    "grad_clipping": 1.0,
    "cuda_device": 0
  }/*,
  "random_seed": 13370,
  "numpy_seed": 1337,
  "pytorch_seed": 133
*/
}
